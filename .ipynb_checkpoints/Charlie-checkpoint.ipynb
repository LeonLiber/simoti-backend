{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from google.cloud import datastore\n",
    "import config\n",
    "import sys,os,os.path\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']='/Users/leoliber/Repos/simoti/ad-server/keyfile.json'\n",
    "ds = datastore.Client(project=config.PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getStopWords(language):\n",
    "  ''' Get explicit stop words by lanauge\n",
    "\n",
    "  Args:\n",
    "    lanaguage (str): 2 characters language name\n",
    "  \n",
    "  Returns:\n",
    "    lanaguage parameter if not found in lookup\n",
    "    else returns a list of stop words\n",
    "  '''\n",
    "\n",
    "  # Hebrew stop words from: https://github.com/stopwords-iso/stopwords-he\n",
    "  stopWords = {\n",
    "    'he': [\"אבל\",\"או\",\"אולי\",\"אותה\",\"אותו\",\"אותי\",\"אותך\",\"אותם\",\"אותן\",\"אותנו\",\"אז\",\"אחר\",\"אחרות\",\"אחרי\",\"אחריכן\",\"אחרים\",\"אחרת\",\"אי\",\"איזה\",\"איך\",\"אין\",\"איפה\",\"איתה\",\"איתו\",\"איתי\",\"איתך\",\"איתכם\",\"איתכן\",\"איתם\",\"איתן\",\"איתנו\",\"אך\",\"אל\",\"אלה\",\"אלו\",\"אם\",\"אנחנו\",\"אני\",\"אס\",\"אף\",\"אצל\",\"אשר\",\"את\",\"אתה\",\"אתכם\",\"אתכן\",\"אתם\",\"אתן\",\"באיזומידה\",\"באמצע\",\"באמצעות\",\"בגלל\",\"בין\",\"בלי\",\"במידה\",\"במקוםשבו\",\"ברם\",\"בשביל\",\"בשעהש\",\"בתוך\",\"גם\",\"דרך\",\"הוא\",\"היא\",\"היה\",\"היכן\",\"היתה\",\"היתי\",\"הם\",\"הן\",\"הנה\",\"הסיבהשבגללה\",\"הרי\",\"ואילו\",\"ואת\",\"זאת\",\"זה\",\"זות\",\"יהיה\",\"יוכל\",\"יוכלו\",\"יותרמדי\",\"יכול\",\"יכולה\",\"יכולות\",\"יכולים\",\"יכל\",\"יכלה\",\"יכלו\",\"יש\",\"כאן\",\"כאשר\",\"כולם\",\"כולן\",\"כזה\",\"כי\",\"כיצד\",\"כך\",\"ככה\",\"כל\",\"כלל\",\"כמו\",\"כן\",\"כפי\",\"כש\",\"לא\",\"לאו\",\"לאיזותכלית\",\"לאן\",\"לבין\",\"לה\",\"להיות\",\"להם\",\"להן\",\"לו\",\"לי\",\"לכם\",\"לכן\",\"למה\",\"למטה\",\"למעלה\",\"למקוםשבו\",\"למרות\",\"לנו\",\"לעבר\",\"לעיכן\",\"לפיכך\",\"לפני\",\"מאד\",\"מאחורי\",\"מאיזוסיבה\",\"מאין\",\"מאיפה\",\"מבלי\",\"מבעד\",\"מדוע\",\"מה\",\"מהיכן\",\"מול\",\"מחוץ\",\"מי\",\"מכאן\",\"מכיוון\",\"מלבד\",\"מן\",\"מנין\",\"מסוגל\",\"מעט\",\"מעטים\",\"מעל\",\"מצד\",\"מקוםבו\",\"מתחת\",\"מתי\",\"נגד\",\"נגר\",\"נו\",\"עד\",\"עז\",\"על\",\"עלי\",\"עליה\",\"עליהם\",\"עליהן\",\"עליו\",\"עליך\",\"עליכם\",\"עלינו\",\"עם\",\"עצמה\",\"עצמהם\",\"עצמהן\",\"עצמו\",\"עצמי\",\"עצמם\",\"עצמן\",\"עצמנו\",\"פה\",\"רק\",\"שוב\",\"של\",\"שלה\",\"שלהם\",\"שלהן\",\"שלו\",\"שלי\",\"שלך\",\"שלכה\",\"שלכם\",\"שלכן\",\"שלנו\",\"שם\",\"תהיה\",\"תחת\"],\n",
    "    'en': list(stop_words.ENGLISH_STOP_WORDS)\n",
    "  }\n",
    "  return stopWords.get(language, 'english') # return specified lanauge if no not found in lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getArticleById(publisherId, articleId):\n",
    "  ''' Get article bu id from Datastore\n",
    "\n",
    "  Args:\n",
    "    publisherId (int): Publisher ID\n",
    "    articleId (int): Article ID\n",
    "\n",
    "  Returns:\n",
    "    Article entity\n",
    "  '''\n",
    "  articleKey = datastore.Key('publishers', publisherId, 'articles', articleId, project=config.PROJECT_ID)\n",
    "  article = ds.get(key=articleKey)\n",
    "  return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFrequencyMatrix(article):\n",
    "    stopWords = getStopWords('en') # Save and get language from article! (not publihser)\n",
    "    vectorizer = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                                   lowercase=True,\n",
    "                                   max_features=None,\n",
    "                                   stop_words = stopWords)\n",
    "    TfIdfMatrix = vectorizer.fit_transform(article)\n",
    "    return (TfIdfMatrix, vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getSnippets():\n",
    "  ''' Get all active snippets\n",
    "\n",
    "  Args:\n",
    "    None\n",
    "\n",
    "  Returns:\n",
    "    Snippets\n",
    "  '''\n",
    "  query = ds.query(kind='snippets')\n",
    "  # query.add_filter('status', '=', 'active') # Doesn't work - WTYF?!!?\n",
    "  return list(query.fetch())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get article dict\n",
    "article = getArticleById('martech.zone', 'ecommerce-shipping-options')\n",
    "(freq, feat) = getFrequencyMatrix([article['content']])\n",
    "freq = freq.toarray()[0]\n",
    "\n",
    "feat.append('MaaS ecosystem') # Add a common word\n",
    "freq = np.append(freq, 1)\n",
    "\n",
    "articleDict = {feat[i]: freq[i] for i in range(0, min(len(feat), len(freq)))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get snippets dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getScoredDicionary(snippets):   \n",
    "    snippetsDict = {}\n",
    "    for i in range(0, len(snippets)):\n",
    "        for j in range(0, len(snippet['wordPouch'])):\n",
    "            featureName = snippets[i]['wordPouch'][j]\n",
    "            snippetsDict[featureName] = snippetsDict.get(featureName, [0] * len(snippets))\n",
    "            snippetsDict[featureName][i] = snippets[i]['wordPouchScores'][j]\n",
    "    return snippetsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snippets = getSnippets()\n",
    "snippetsDict = getScoredDicionary(snippets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common words between all 2 snippets: ['Africa rose']\n"
     ]
    }
   ],
   "source": [
    "# Common words between all snippets\n",
    "commonWords = [dup for dup in snippetsDict if 0 not in snippetsDict[dup]]\n",
    "print('Common words between all {} snippets:'.format(len(snippets)), commonWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.32148986304024385, 0]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiply dictionaries\n",
    "commonWordsBag = {}\n",
    "snippetScores = [0] * len(snippets)\n",
    "for i in range(0, len(snippets)):\n",
    "    for key in articleDict.keys():\n",
    "        keyScore = articleDict[key] * snippetsDict.get(key, [0] * len(snippets))[i]\n",
    "        if(keyScore > 0):\n",
    "            snippetScores[i] = snippetScores[i] + keyScore\n",
    "            commonWordsBag[i] = commonWordsBag.get(i, set()) | {key}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
